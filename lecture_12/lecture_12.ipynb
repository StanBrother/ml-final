{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccf85ad-f3f0-4aa2-a472-d8c16cff73db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:49:40.539130149Z",
     "start_time": "2024-06-07T11:49:40.529352966Z"
    },
    "collapsed": true
   },
   "source": [
    "# ლექცია #12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df184466-df74-45b7-b547-3410deb86b1b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## კოდების გაშვებისთვის საჭირო ბიბლიოთეკების იმპორტები"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104f0c0-2c2c-4196-8f1d-245761ccb675",
   "metadata": {},
   "source": [
    "ამ ნოუთბუქის გაშვებამდე არ დაგავიწყდეთ საჭირო დამოკიდებულებების (dependencies) დაინსტალირება, რომლებიც მოცემულია `requirements.txt` ფაილში. მარტივად, ტერმინალიდან გაუშვით:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da138b0a-e063-49b0-9c56-937a9a9bd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64da42-d5ad-4b15-acc4-a5104d2d9ff9",
   "metadata": {},
   "source": [
    "## მონაცემების ჩატვირთვა"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22517482-9196-4528-b39d-dcb1712bc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7754d10-ac97-4e37-bfa7-909964159a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data.data,\n",
    "    iris_data.target,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=iris_data.target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7de2a1-78af-43a6-814f-ba6b7e569efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"სატრენინგო მონაცემების ზომა:\", X_train.shape, y_train.shape)\n",
    "print(\"სატესტო მონაცემების ზომა:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b8c1a-0047-4479-b889-fb9e63966647",
   "metadata": {},
   "source": [
    "## ჯვარედინი ვალიდაცია"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8caa0-34f1-4220-9090-2676a2d43861",
   "metadata": {},
   "source": [
    "ჯვარედინი ვალიდაცია ML-ში არის ტექნიკა, რომელიც გამოიყენება მოდელის პერფორმანსის და განზოგადების შესაფასებლად. იგი მოიცავს მონაცემთა ნაკრების მრავალ ქვეჯგუფად დაყოფას, მოდელის დატრენინგებას ზოგიერთ ქვეჯგუფზე (სატრენინგო მონაცემები) და მის ვალიდაციას დანარჩენ ქვეჯგუფზე (ვალიდაციის მონაცემები). ეს პროცესი რამდენჯერმე მეორდება სხვადასხვა ქვეჯგუფებთან, რათა უზრუნველყოს მოდელის სტაბილურობა და შემცირდეს \"ზედმეტად მორგება\".\n",
    "\n",
    "სხვადასხვა ტიპის ჯვარედინი ვალიდაციის ტექნიკა არსებობს:\n",
    "\n",
    "* **k-Fold**: მონაცემები დაყოფილია k თანაბარი ზომის ნაწილად და თითოეული ნაწილი გამოიყენება ვალიდაციის მონაცემებად ერთხელ, ხოლო დარჩენილი k-1 ნაწილები გამოიყენება ტრენინგისთვის.\n",
    "* **Stratified k-Fold Cross-Validation**: k-fold-ის მსგავსია, თუმცა უზრუნველყოფს, რომ თითოეულ ნაწილში კლასების იგივე პროპორცია იყოს, როგორც თავდაპირველ მონაცემთა ნაკრებში.\n",
    "* **Repeated k-Fold Cross-Validation**: k-fold ჯვარედინი ვალიდაციის პროცესი მეორდება რამდენჯერმე, თუმცა ყოველ ჯერზე მონაცემების სხვადასხვა შემთხვევითი გაყოფით.\n",
    "* **Leave-One-Out Cross-Validation (LOOCV)**: თითოეული დაკვირვება/მაგალითი მონაცემთა ნაკრებში გამოიყენება ვალიდაციის მონაცემად ერთხელ და დანარჩენი მაგალითები გამოიყენება სატრენინგო მონაცემებად.\n",
    "* **Leave-p-Out Cross-Validation (LpOCV)**: LOOCV-ის მსგავსია, თუმცა ერთი დაკვირვების ნაცვლად, p რაოდენობის მაგალითია გამოყენებული ვალიდაციისთვის და მოდელი ტრენინგდება დანარჩენ დაკვირვებებზე.\n",
    "* **Time Series Cross-Validation**: გამოიყენება დროით მწკრივებზე, სადაც მონაცემების თანმიმდევრობა მნიშვნელოვანია. მონაცემები იყოფა ისე, რომ ტრენინგი ხდება წარსულ მონაცემებზე, ხოლო ვალიდაცია - მომავლის/ახლანდელ მონაცემებზე."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5edb8-29c9-4d2c-9003-eb4b6fa1db1a",
   "metadata": {},
   "source": [
    "### Stratified k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24a4a0-9215-4192-8fb7-08d5c0c3c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for fold_n, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train), start=1):\n",
    "    print(f\"Fold #{fold_n}\\n\")\n",
    "\n",
    "    X_train_new, X_valid = X_train[train_idx], X_train[valid_idx]\n",
    "    y_train_new, y_valid = y_train[train_idx], y_train[valid_idx]\n",
    "\n",
    "    log_reg = LogisticRegression(random_state=1)\n",
    "    log_reg.fit(X_train_new, y_train_new)\n",
    "\n",
    "    train_preds = log_reg.predict(X_train_new)\n",
    "    train_score = accuracy_score(y_train_new, train_preds)\n",
    "    print(\"სატრენინგო მონაცემები:\")\n",
    "    print(f\"\\tდაკვირვებების რაოდენობა: {len(y_train_new)}\")\n",
    "    print(f\"\\tSetosa-ს რაოდენობა: {(y_train_new == 0).sum()}\")\n",
    "    print(f\"\\tVersicolor-ის რაოდენობა: {(y_train_new == 1).sum()}\")\n",
    "    print(f\"\\tVirginica-ს რაოდენობა: {(y_train_new == 2).sum()}\")\n",
    "    print(f\"\\tაკურატულობა: {train_score * 100:.2f}%\")\n",
    "    train_accuracies.append(train_score)\n",
    "\n",
    "    print()\n",
    "\n",
    "    valid_preds = log_reg.predict(X_valid)\n",
    "    valid_score = accuracy_score(y_valid, valid_preds)\n",
    "    print(\"ვალიდაციის მონაცემები:\")\n",
    "    print(f\"\\tდაკვირვებების რაოდენობა: {len(y_valid)}\")\n",
    "    print(f\"\\tSetosa-ს რაოდენობა: {(y_valid == 0).sum()}\")\n",
    "    print(f\"\\tVersicolor-ის რაოდენობა: {(y_valid == 1).sum()}\")\n",
    "    print(f\"\\tVirginica-ს რაოდენობა: {(y_valid == 2).sum()}\")\n",
    "    print(f\"\\tაკურატულობა: {valid_score * 100:.2f}%\")\n",
    "    valid_accuracies.append(valid_score)\n",
    "\n",
    "    print()\n",
    "\n",
    "mean_train_score = sum(train_accuracies) / len(train_accuracies)\n",
    "mean_valid_score = sum(valid_accuracies) / len(valid_accuracies)\n",
    "\n",
    "print(f\"საშუალო აკურატულობა სატრენინგო მონაცემებზე: {mean_train_score * 100:.2f}%\")\n",
    "print(f\"საშუალო აკურატულობა ვალიდაციის მონაცემებზე: {mean_valid_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6211e1b-7021-45a6-952f-7817b3e36bb0",
   "metadata": {},
   "source": [
    "## ჰიპერპარამეტრების ოპტიმიზაცია (Hyperparameter Optimization - HPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688d55c-c5c3-4a0b-b241-454ffa76f9e2",
   "metadata": {},
   "source": [
    "**ჰიპერპარამეტრები** არის პარამეტრები, რომლებიც უნდა განისაზღვროს ტრენინგის პროცესის დაწყებამდე. ისინი არ არის ნასწავლი მონაცემებიდან, არამედ დეველოპერის/მეცნიერის მიერ არის განსაზღვრული. ჰიპერპარამეტრების მაგალითებია `n_estimators`, `max_depth` და `max_features` `RandomForestClassifier`-ში.\n",
    "\n",
    "ჰიპერპარამეტრების ოპტიმიზაცია არის ML მოდელისთვის ჰიპერპარამეტრების საუკეთესო ნაკრების პოვნის პროცესი. მისი მიზანია მოდელის მუშაობის გაუმჯობესება ყველაზე შესაფერისი/ოპტიმალური ჰიპერპარამეტრების შერჩევით."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de92eca-dab2-4364-9202-d7a90384e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_valid, y_train_new, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.15,\n",
    "    random_state=1,\n",
    "    stratify=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce15b0-bb4b-497f-be19-accb9dfb7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"სატრენინგო მონაცემების ზომა:\", X_train_new.shape, y_train_new.shape)\n",
    "print(\"ვალიდაციის მონაცემების ზომა:\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795d6df-0060-48fa-bd2a-59613105b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "train_score = 0\n",
    "best_params = None\n",
    "\n",
    "for n_estimators in range(3, 6):\n",
    "    for max_features in [\"log2\", \"sqrt\", None]:\n",
    "        for max_depth in range(3, 6):\n",
    "            rf = RandomForestClassifier(\n",
    "                random_state=1,\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "            )\n",
    "            rf.fit(X_train_new, y_train_new)\n",
    "\n",
    "            valid_score = accuracy_score(y_valid, rf.predict(X_valid))\n",
    "            if valid_score > best_score:\n",
    "                train_score = accuracy_score(y_train_new, rf.predict(X_train_new))\n",
    "                best_score = valid_score\n",
    "                best_params = {\n",
    "                    \"n_estimators\": n_estimators,\n",
    "                    \"max_features\": max_features,\n",
    "                    \"max_depth\": max_depth,\n",
    "                }\n",
    "print(f\"საუკეთესო აკურატულობა ვალიდაციის მონაცემებზე: {best_score * 100:.2f}%\")\n",
    "print(f\"აკურატულობა სატრენინგო მონაცემებზე: {train_score * 100:.2f}%\")\n",
    "print(f\"ოპტიმალური პარამეტრები: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e572f90-072d-4d6c-b780-6450b7579393",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8478d6-5d5c-470a-8019-0a01033106ed",
   "metadata": {},
   "source": [
    "\"Grid Search with Cross-Validation\" შეგვიძლია გამოვიყენოთ მოდელის ჰიპერპარამეტრების ოპტიმიზაციისთვის. როგორც სახელი მიანიშნებს, ის იყენებს ჯვარედინ ვალიდაციას. \"Grid\" მიუთითებს ამომწურავ ძიებაზე ჰიპერპარამეტრული სივრცის ხელით მითითებულ მნიშვნელობებზე. მაგალითად, თუ გვაქვს ორი ჰიპერპარამეტრი სამი შესაძლო მნიშვნელობით, `GridSearchCV` შეაფასებს ამ ჰიპერპარამეტრების $3 \\times 3 = 9$ კომბინაციას. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b2e58-dd72-4da6-8eba-764d09af9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": range(3, 6),\n",
    "    \"max_features\": [\"log2\", \"sqrt\", None],\n",
    "    \"max_depth\": range(3, 6),\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    "    refit=True,\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6cd75-5c1b-443e-a29f-2ede1a81325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"საუკეთესო საშუალო აკურატულობა: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"ოპტიმალური ჰიპერპარამეტრები: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92999b31-77af-4515-94aa-723dfa42e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"საუკეთესო მოდელის საშუალო აკურატულობა სატრენინგო მონაცემებზე: \"\n",
    "    f\"{grid.cv_results_['mean_train_score'][grid.best_index_] * 100:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    \"საუკეთესო მოდელის საშუალო აკურატულობა ვალიდაციის მონაცემებზე: \"\n",
    "    f\"{grid.cv_results_['mean_test_score'][grid.best_index_] * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df168d2-ebae-4da4-a187-a2575835faea",
   "metadata": {},
   "source": [
    "რადგანაც `refit`-ში გადავეცით True, ეს ნიშნავს, რომ საუკეთესო მოდელი ხელახლა დატრენინგდა მთლიანი მონაცემებით ოპტიმალური ჰიპერპარამეტრების გამოყენებით. თუმცა შეგვიძლია თავადაც დავატრენინგოთ საბოლოო მოდელი."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373ac9c-3ff4-4ada-b1e2-57089f13981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1, **grid.best_params_)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1224139a-aa7a-465c-9f1d-e799507f8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.predict(X_test) == rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3925f4c-372b-4e60-93c5-84e7cf042f68",
   "metadata": {},
   "source": [
    "როგორც ვხედავთ, პროგნოზები სატესტო მონაცემებზე იდენტურია, რადგანაც რეალურად ერთი და იმავე პარამეტრებით დატრენინგებული მოდელები გვაქვს."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93838cc6-e735-4a74-b907-b028e91b3ca1",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6c84e-99dd-496a-bd92-14c79b749d05",
   "metadata": {},
   "source": [
    "\"Randomized Search with Cross-Validation\" `GridSearchCV`-ის მსგავსად შეგვიძლია გამოვიყენოთ მოდელის ჰიპერპარამეტრების ოპტიმიზაციისთვის ჯვარედინი ვალიდაციის გამოყენებით. თუმცა, იმის ნაცვლად, რომ სცადოს ჰიპერპარამეტრების ყველა შესაძლო კომბინაცია (როგორც `GridSearchCV`-ში), ის ამოწმებს ჰიპერპარამეტრების კომბინაციების ფიქსირებულ რაოდენობას მითითებული განაწილებიდან. შესაბამისად, უფრო ეფექტურია, როდესაც უზარმაზარი ჰიპერპარამეტრების სივრციდან გვსურს ოპტიმალური პარამეტრების ამორჩევა."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a058c8-d41c-4e93-9426-0159bf38af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": range(3, 6),\n",
    "    \"max_features\": [\"log2\", \"sqrt\", None],\n",
    "    \"max_depth\": range(3, 6),\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_iter=15,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    "    random_state=1,\n",
    ")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e718405-ee88-4687-bb55-bb56934482e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"საუკეთესო საშუალო აკურატულობა: {random_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"ოპტიმალური ჰიპერპარამეტრები: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ade1a3-5029-4c56-bd65-7e8e3a125003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"საუკეთესო მოდელის საშუალო აკურატულობა სატრენინგო მონაცემებზე: \"\n",
    "    f\"{random_search.cv_results_['mean_train_score'][random_search.best_index_] * 100:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    \"საუკეთესო მოდელის საშუალო აკურატულობა ვალიდაციის მონაცემებზე: \"\n",
    "    f\"{random_search.cv_results_['mean_test_score'][random_search.best_index_] * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db361e-26e6-4012-a337-10b23c86b8f7",
   "metadata": {},
   "source": [
    "აქაც `refit`-ში გადაცემული True-ს გამო საუკეთესო მოდელი ხელახლა დატრენინგდა მთლიანი მონაცემებით ოპტიმალური ჰიპერპარამეტრების გამოყენებით:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95024609-5bf2-4c1c-8963-55342c36d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1, **random_search.best_params_)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee50dc-1b67-4d37-a7d7-d6c45537f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_.predict(X_test) == rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478fabb0-6f96-41a1-9335-751baea55fb4",
   "metadata": {},
   "source": [
    "### საბოლოო მოდელის განზოგადების ნახვა"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a29dc-c0d7-4947-af57-b890c76313ef",
   "metadata": {},
   "source": [
    "როდესაც HPO-თი ვიპოვით საუკეთესო ჰიპერპარამეტრებს, ამ პარამეტრებით უნდა დატრენინგდეს საბოლოო მოდელი და რა თქმა უნდა, უნდა ვნახოთ მისი განზოგადების უნარი უნახავ, გადადებულ სატესტო, მონაცემებზე:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df1e5f-1e4c-4e2d-9318-f772712ab1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    random_state=1, n_estimators=3, max_features=\"log2\", max_depth=5\n",
    ")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bc174-5dc1-4d1f-bdc6-d1e5cb824b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = rf.predict(X_train)\n",
    "test_preds = rf.predict(X_test)\n",
    "\n",
    "print(\n",
    "    \"აკურატულობა სატრენინგო მონაცემებზე: \"\n",
    "    f\"{accuracy_score(y_train, train_preds) * 100:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    \"აკურატულობა სატესტო მონაცემებზე: \"\n",
    "    f\"{accuracy_score(y_test, test_preds) * 100:.2f}%\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
